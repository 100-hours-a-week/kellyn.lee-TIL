# 25.02.12.Wed - TIL

### [오늘 할 일]

- 금일 강의 내용 학습(복습) 및 정리
    - SciPy 심화 강의 : 정규 분포
- 3주차 데이터 시각화 미니퀘스트 진행
    - 정형 데이터 + 비정형 데이터

---

### [기타]

- **평균, Mean, μ** : **데이터의 중심값**, 모든 값의 합을 데이터 개수로 나눈 값
- **분산, Variance** : 평균에서 각 데이터가 얼마나 떨어져 있는지(**흩어진 정도**) 나타냄
    - 데이터가 평균에서 얼마나 멀리 분포하는지 나타냄
    - 값이 클수록 데이터가 평균에서 많이 퍼져 있음
- **표준편차, Standard Deviation**
    
    : 분산은 제곱 값이므로 실제 값과 단위가 달라지기 때문에, **제곱근을 씌워** 원래 단위로 변환한 값
    
    - 분산을 원래 단위로 변환하여 데이터의 변동성을 쉽게 해석
    - 표준편차가 작으면 데이터가 평균에 가깝게 모여 있고, 크면 넓게 퍼져 있음
    - 표준편차가 0이면 모든 데이터가 같은 값

---

## [확률과 선형 모델링의 기초 개념 정리]

### LLM과 수학적 개념의 연관성

- LLM 모델이 흉내내려는 원래의 것 : 인간의 뇌
- 인공 뇌에게 일을 시킬 것 : 일 = 계산
- 선형 계산 : 선형 대수
- 모델링을 하고 싶은 대상에 대한 모델을 최대한 단순한 걸로 해야함. 선형 모델 : 선형 근사 : 미분
- 적분 : 확률



### 확률, Probability

- **확률** : 사건의 발생 가능성을 수학적으로 나타내는 통계 개념
- 한 사건의 확률 : 0과 1 사이의 수
    - 0 : 절대 발생하지 않음
    - 1 : 반드시 발생함
        
        → 값이 클수록 사건이 일어날 가능성이 높음
        
- 확률이 크면 클수록 그 사건이 더 잘 일어날 것 같다.
- **사건, events** : 시행 결과의 부분집합
- **표본 공간, Sample Space, S** : **시행의 모든 결과**를 모은 집합
    - 시행 : 동전을 (한 번) 던짐
    - 결과 : 앞면(H), 뒷면(T)
    - 표본 공간 : S = {H, T}
    - 사건 : S의 부분 집합
        1. 사건 E = {H, T}
            1. 동전을 던졌는데 결과가 H → 사건 E가 발생하였나? Yes (H in E)
        2. 사건 E = {H}
            1. 동전을 던졌는데 결과가 T → 사건 E가 발생하였나? No (H !in E)
        3. 사건 E = { }
            1. 동전을 던졌을 때 뭐라도 나옴 → 사건 E가 발생하였나? No




### 확률 분포의 유형

- **이산 표본 공간, Discrete Probability Distribution**
 : 이산 떨어져 있다 / ex. 범주형 데이터
    - 이산적인 값 : 개별적으로 구분되는 값
- **연속 표본 공간, Continuout Probability Distribution** 
: 시행의 결과가 실수 값(연속 값) / ex. 키, 무게, 시험 점수




### 확률 밀도와 질량

- **이산 확률에서 확률 질량 함수, PMF, Probability Mass Function**
    - 특정한 값이 나올 확률을 직접 계산 가능
        
        ex. 동전 던지기에서 P(H) = 0.5
        
- **연속 확률에서 확률 밀도 함수, PDF, Probability Density Function**
    - 특정한 값 하나가 나올 확률을 0 (부피 개념)
    - 특정한 구간 내에서 확률을 계산해야 함 (적분 활용)
        
        ex. 사람의 키가 170cm일 확률을 계산하는 것이 아니라, “170~175cm 사이에 있을 확률”을 구함.
    

*※ 질량과 밀도(농도) = 부피/질량 ※*
*※ 연속적인 값들(어느쪽) = 부피 ※*




### 선형 모델과 확률

- **선형 모델** : 복잡한 현상을 단순한 선형 근사로 표현
    - 머신러닝에서 **선형 회귀**(Linear Regression)가 대표적
    - 선형 변환(행렬 곱셈 등)을 이용하여 데이터를 학습
- 미분과 선형 근사
    - 미분, differentiation : 변화율을 구하여 최적의 선형 근사를 찾는 과정
        ex. 손실 함수(loss function)의 기울기를 계산하여 모델을 최적화 
- 적분과 확률
    - 확률 밀도 함수(PDF)에서 특정 구간의 확률을 구할 때 적분 사용
    - 연속 확률 분포에서 누적 분포 함수(CDF) 계산




### 결론

- 통계는 세상을 전체로 꿰뚫어 보는 것



